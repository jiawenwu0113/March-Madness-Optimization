{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import march_madness\n",
    "import dq_learning\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dq_learning' from '/Users/kenzeng/Desktop/College/DSCI/RL/Final-Project/March-Madness-Optimization/dq_learning.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(march_madness)\n",
    "importlib.reload(dq_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 1, 16)             1104      \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 1, 16)             0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1, 32)             544       \n",
      "                                                                 \n",
      " activation_37 (Activation)  (None, 1, 32)             0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1, 2)              66        \n",
      "                                                                 \n",
      " activation_38 (Activation)  (None, 1, 2)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,714\n",
      "Trainable params: 1,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m dq_learning\u001b[39m.\u001b[39;49mtrain_model(EPOCHS\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/College/DSCI/RL/Final-Project/March-Madness-Optimization/dq_learning.py:73\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(EPOCHS, epsilon, EPSILON_REDUCE, LEARNING_RATE)\u001b[0m\n\u001b[1;32m     69\u001b[0m     points \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     71\u001b[0m     \u001b[39m# Train the model by replaying\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[39m#print(f\"*** Debug: Done = {done}\")\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     replay(replay_buffer, \u001b[39m32\u001b[39;49m, model, target_model)\n\u001b[1;32m     75\u001b[0m epsilon \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m EPSILON_REDUCE  \u001b[39m# Reduce epsilon\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m# Check if we need to update the target model\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/College/DSCI/RL/Final-Project/March-Madness-Optimization/dq_learning.py:177\u001b[0m, in \u001b[0;36mreplay\u001b[0;34m(replay_buffer, batch_size, model, target_model)\u001b[0m\n\u001b[1;32m    174\u001b[0m     target_batch\u001b[39m.\u001b[39mappend(target)\n\u001b[1;32m    176\u001b[0m \u001b[39m# Fit the model based on the states and the updated targets for 1 epoch\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m model\u001b[39m.\u001b[39;49mfit(np\u001b[39m.\u001b[39;49marray(states), np\u001b[39m.\u001b[39;49marray(target_batch), epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1217\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:975\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    973\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    976\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[1;32m    978\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    979\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3129\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3126\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   3127\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[0;32m-> 3129\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m   3131\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3557\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3553\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3554\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3556\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mmissed\u001b[39m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3557\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   3558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mprimary[cache_key] \u001b[39m=\u001b[39m graph_function\n\u001b[1;32m   3560\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3392\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3387\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   3388\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3389\u001b[0m ]\n\u001b[1;32m   3390\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   3391\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3392\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   3393\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   3394\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   3395\u001b[0m         args,\n\u001b[1;32m   3396\u001b[0m         kwargs,\n\u001b[1;32m   3397\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   3398\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   3399\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   3400\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   3401\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[1;32m   3402\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   3403\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   3404\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   3405\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3406\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3408\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3409\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3410\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1143\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1143\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1145\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1148\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:672\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    669\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    670\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 672\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    673\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1118\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1118\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1119\u001b[0m       original_func,\n\u001b[1;32m   1120\u001b[0m       args,\n\u001b[1;32m   1121\u001b[0m       kwargs,\n\u001b[1;32m   1122\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1123\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1124\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1125\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1126\u001b[0m       ))\n\u001b[1;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:445\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 445\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    446\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/l9/d92rqdzj2sq_zvz6kr_11_hh0000gn/T/__autograph_generated_filetl4gvzkt.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:337\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    336\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 337\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    340\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 465\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/keras/engine/training.py:867\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mreturn\u001b[39;00m outputs\n\u001b[1;32m    866\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m--> 867\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m    868\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    869\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    870\u001b[0m write_scalar_summaries(outputs, step\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39m_train_counter)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2892\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2890\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2891\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2892\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3695\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3694\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 3695\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:696\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 696\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    698\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:383\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    380\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 383\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    385\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:464\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    465\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/keras/engine/training.py:860\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m--> 860\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m    861\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m    862\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/keras/engine/training.py:816\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    812\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    813\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTarget data is missing. Your model has `loss`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    814\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mand therefore expects target data to be passed in `fit()`.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    815\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m--> 816\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[1;32m    817\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_metrics\u001b[39m.\u001b[39mupdate_state(y, y_pred, sample_weight)\n\u001b[1;32m    818\u001b[0m \u001b[39m# Collect metrics to return\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:532\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \n\u001b[1;32m    502\u001b[0m \u001b[39mThis method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m \n\u001b[1;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_gradients(\n\u001b[1;32m    531\u001b[0m     loss, var_list\u001b[39m=\u001b[39mvar_list, grad_loss\u001b[39m=\u001b[39mgrad_loss, tape\u001b[39m=\u001b[39mtape)\n\u001b[0;32m--> 532\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:672\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    669\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[1;32m    671\u001b[0m \u001b[39mif\u001b[39;00m optimizer_utils\u001b[39m.\u001b[39mstrategy_supports_no_merge_call():\n\u001b[0;32m--> 672\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distributed_apply(strategy, grads_and_vars, name,\n\u001b[1;32m    673\u001b[0m                                  apply_state)\n\u001b[1;32m    674\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m    676\u001b[0m       functools\u001b[39m.\u001b[39mpartial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distributed_apply, apply_state\u001b[39m=\u001b[39mapply_state),\n\u001b[1;32m    677\u001b[0m       args\u001b[39m=\u001b[39m(grads_and_vars,),\n\u001b[1;32m    678\u001b[0m       kwargs\u001b[39m=\u001b[39m{\n\u001b[1;32m    679\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: name,\n\u001b[1;32m    680\u001b[0m       })\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:721\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[39mwith\u001b[39;00m distribution\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mcolocate_vars_with(var):\n\u001b[1;32m    718\u001b[0m   \u001b[39mwith\u001b[39;00m name_scope_only_in_function_or_graph(\n\u001b[1;32m    719\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m eagerly_outside_functions \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mupdate_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m    720\u001b[0m       var\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mname):\n\u001b[0;32m--> 721\u001b[0m     update_op \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39;49mextended\u001b[39m.\u001b[39;49mupdate(\n\u001b[1;32m    722\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39;49m(grad,), group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    723\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39min_cross_replica_context():\n\u001b[1;32m    724\u001b[0m       \u001b[39m# In cross-replica context, extended.update returns a list of\u001b[39;00m\n\u001b[1;32m    725\u001b[0m       \u001b[39m# update ops from all replicas (group=False).\u001b[39;00m\n\u001b[1;32m    726\u001b[0m       update_ops\u001b[39m.\u001b[39mextend(update_op)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2636\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2635\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2636\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_replica_ctx_update(\n\u001b[1;32m   2637\u001b[0m       var, fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, group\u001b[39m=\u001b[39;49mgroup)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2515\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_fn\u001b[39m(_, \u001b[39m*\u001b[39mmerged_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerged_kwargs):\n\u001b[1;32m   2513\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(var, fn, merged_args, merged_kwargs, group\u001b[39m=\u001b[39mgroup)\n\u001b[0;32m-> 2515\u001b[0m \u001b[39mreturn\u001b[39;00m replica_context\u001b[39m.\u001b[39;49mmerge_call(merge_fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3101\u001b[0m, in \u001b[0;36mReplicaContextBase.merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_call\u001b[39m(\u001b[39mself\u001b[39m, merge_fn, args\u001b[39m=\u001b[39m(), kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3075\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Merge args across replicas and run `merge_fn` in a cross-replica context.\u001b[39;00m\n\u001b[1;32m   3076\u001b[0m \n\u001b[1;32m   3077\u001b[0m \u001b[39m  This allows communication and coordination when there are multiple calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3099\u001b[0m \u001b[39m    unpacked.\u001b[39;00m\n\u001b[1;32m   3100\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3101\u001b[0m   require_replica_context(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   3102\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:333\u001b[0m, in \u001b[0;36mrequire_replica_context\u001b[0;34m(replica_ctx)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequire_replica_context\u001b[39m(replica_ctx):\n\u001b[1;32m    332\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Verify in `replica_ctx` replica context.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m   context \u001b[39m=\u001b[39m _get_per_thread_mode()\n\u001b[1;32m    334\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mreplica_context \u001b[39mis\u001b[39;00m replica_ctx: \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    335\u001b[0m   \u001b[39m# We have an error to report, figure out the right message.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/distribute/distribution_strategy_context.py:82\u001b[0m, in \u001b[0;36m_get_per_thread_mode\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_per_thread_mode\u001b[39m():\n\u001b[1;32m     81\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mget_default_graph()\u001b[39m.\u001b[39m_distribution_strategy_stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     83\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mIndexError\u001b[39;00m):\n\u001b[1;32m     84\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_default_replica_mode()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:6231\u001b[0m, in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6206\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mget_default_graph\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   6207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_default_graph\u001b[39m():\n\u001b[1;32m   6208\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns the default graph for the current thread.\u001b[39;00m\n\u001b[1;32m   6209\u001b[0m \n\u001b[1;32m   6210\u001b[0m \u001b[39m  The returned graph will be the innermost graph on which a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6229\u001b[0m \u001b[39m    The default `Graph` being used in the current thread.\u001b[39;00m\n\u001b[1;32m   6230\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6231\u001b[0m   \u001b[39mreturn\u001b[39;00m _default_graph_stack\u001b[39m.\u001b[39;49mget_default()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5738\u001b[0m, in \u001b[0;36m_DefaultGraphStack.get_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5736\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Override that returns a global default if the stack is empty.\"\"\"\u001b[39;00m\n\u001b[1;32m   5737\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack:\n\u001b[0;32m-> 5738\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[1;32m   5739\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_global_default_graph:\n\u001b[1;32m   5740\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_global_default_graph\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = dq_learning.train_model(EPOCHS=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Alabama', 0.986018306539), ('Texas A&M-Corpus Christi', 0.541225582728), ('Southeast Missouri State', 0.458774417272), ('Maryland', 0.508126527565), ('West Virginia', 0.491873472435), ('San Diego State', 0.669242707259), ('College of Charleston', 0.330757292741), ('Virginia', 0.721410837696), ('Furman', 0.278589162304), ('Creighton', 0.785335862297), ('North Carolina State', 0.214664137703), ('Baylor', 0.889010974131), ('UC-Santa Barbara', 0.110989025869), ('Missouri', 0.359265360637), ('Utah State', 0.640734639363), ('Arizona', 0.935394107206), ('Princeton', 0.064605892794), ('Purdue', 0.984874377903), ('Texas Southern', 0.567976714791), ('Fairleigh Dickinson', 0.432023285209), ('Memphis', 0.641222075137), ('Florida Atlantic', 0.358777924863), ('Duke', 0.819032265834), ('Oral Roberts', 0.180967734166), ('Tennessee', 0.867605166121), ('Louisiana-Lafayette', 0.132394833879), ('Kentucky', 0.66448807198), ('Providence', 0.33551192802), ('Kansas State', 0.8514079072), ('Montana State', 0.1485920928), ('Michigan State', 0.63702703821), ('Southern California', 0.36297296179), ('Marquette', 0.889203262725), ('Vermont', 0.110796737275), ('Houston', 0.971047546794), ('Northern Kentucky', 0.028952453206), ('Iowa', 0.419077202952), ('Auburn', 0.580922797048), ('Miami (FL)', 0.594447595581), ('Drake', 0.405552404419), ('Indiana', 0.737316538224), ('Kent State', 0.262683461776), ('Iowa State', 0.575664349556), ('Mississippi State', 0.565969715321), ('Pittsburgh', 0.434030284679), ('Xavier', 0.874221895799), ('Kennesaw State', 0.125778104201), ('Texas A&M', 0.604012449912), ('Penn State', 0.395987550088), ('Texas', 0.921391658573), ('Colgate', 0.078608341427), ('Kansas', 0.97820868499), ('Howard', 0.02179131501), ('Arkansas', 0.515279284319), ('Illinois', 0.484720715681), (\"Saint Mary's (CA)\", 0.585061934196), ('Virginia Commonwealth', 0.414938065804), ('Connecticut', 0.846392029328), ('Iona', 0.153607970672), ('Texas Christian', 0.678964288393), ('Arizona State', 0.543726386334), ('Nevada', 0.456273613666), ('Gonzaga', 0.91632414588), ('Grand Canyon', 0.08367585412), ('Northwestern', 0.41267379587), ('Boise State', 0.58732620413), ('UCLA', 0.954593616356), ('North Carolina-Asheville', 0.045406383644)])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploit_model(model):\n",
    "    env = march_madness.MarchMadnessEnvironment()\n",
    "    observation, info = env.reset()\n",
    "    total_reward = 0 \n",
    "    done = False\n",
    "    while not done:\n",
    "        # Choose action from predicted Q-values\n",
    "        observations =  tf.reshape(\n",
    "            tf.constant(list(observation.values())),\n",
    "            (1,1,-1)\n",
    "        )\n",
    "        action = np.argmax(model.predict(observations)) \n",
    "        \n",
    "        # Perform the action \n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_reward  += reward\n",
    "        # clear_output(wait=True)\n",
    "        \n",
    "        if done:\n",
    "            print(f\"Total Reward: {total_reward}\")\n",
    "            env.reset()\n",
    "            #break\n",
    "            \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: 361.6898711855939\n"
     ]
    }
   ],
   "source": [
    "exploit_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.2412432],\n",
       "       [2.234242 ]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(\n",
    "    tf.constant(list({\"a\":1.2412432, \"b\":2.234242}.values())), \n",
    "    (-1,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = march_madness.MarchMadnessEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(dict_values([0.986018306539, 0.541225582728, 0.458774417272, 0.508126527565, 0.491873472435, 0.669242707259, 0.330757292741, 0.721410837696, 0.278589162304, 0.785335862297, 0.214664137703, 0.889010974131, 0.110989025869, 0.359265360637, 0.640734639363, 0.935394107206, 0.064605892794, 0.984874377903, 0.567976714791, 0.432023285209, 0.641222075137, 0.358777924863, 0.819032265834, 0.180967734166, 0.867605166121, 0.132394833879, 0.66448807198, 0.33551192802, 0.8514079072, 0.1485920928, 0.63702703821, 0.36297296179, 0.889203262725, 0.110796737275, 0.971047546794, 0.028952453206, 0.419077202952, 0.580922797048, 0.594447595581, 0.405552404419, 0.737316538224, 0.262683461776, 0.575664349556, 0.565969715321, 0.434030284679, 0.874221895799, 0.125778104201, 0.604012449912, 0.395987550088, 0.921391658573, 0.078608341427, 0.97820868499, 0.02179131501, 0.515279284319, 0.484720715681, 0.585061934196, 0.414938065804, 0.846392029328, 0.153607970672, 0.678964288393, 0.543726386334, 0.456273613666, 0.91632414588, 0.08367585412, 0.41267379587, 0.58732620413, 0.954593616356, 0.045406383644]),\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.array(observations.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 1, 16)             1104      \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 1, 16)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1, 32)             544       \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 1, 32)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1, 2)              66        \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 1, 2)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,714\n",
      "Trainable params: 1,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "\n        'EagerTensor' object has no attribute 'reshape'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_model()\n",
      "File \u001b[0;32m~/Desktop/College/DSCI/RL/Final-Project/March-Madness-Optimization/model.py:45\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(EPOCHS, epsilon, EPSILON_REDUCE, LEARNING_RATE)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     44\u001b[0m     observation, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()  \u001b[39m# Get inital state\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     observation \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconstant(\u001b[39mlist\u001b[39;49m(observation\u001b[39m.\u001b[39;49mvalues()))\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m     \u001b[39m# Keras expects the input to be of shape [1, X] thus we have to reshape\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[39m# [Jeremy] Original state is an array of shape (4): [Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity]\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \n",
      "File \u001b[0;32m/opt/anaconda3/envs/flappy/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:437\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m    434\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mravel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtranspose\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclip\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    435\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mtolist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    438\u001b[0m \u001b[39m      \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    439\u001b[0m \u001b[39m      If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    440\u001b[0m \u001b[39m      from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[1;32m    441\u001b[0m \u001b[39m      np_config.enable_numpy_behavior()\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n\u001b[1;32m    442\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \n        'EagerTensor' object has no attribute 'reshape'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()"
     ]
    }
   ],
   "source": [
    "model = model.train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
